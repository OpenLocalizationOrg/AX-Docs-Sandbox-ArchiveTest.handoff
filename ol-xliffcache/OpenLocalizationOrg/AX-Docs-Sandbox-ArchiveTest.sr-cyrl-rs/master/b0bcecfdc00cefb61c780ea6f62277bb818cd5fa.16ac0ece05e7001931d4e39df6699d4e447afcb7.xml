{"content":"---\n# required metadata\n\ntitle: Recurring integrations\ndescription: This article provides information about recurring integrations. The process of data migration, and movement into and out of any enterprise system, is a critical piece that any platform must support. \nauthor: RobinARH\nmanager: AnnBe\nms.date: 06/20/2017\nms.topic: article\nms.prod: \nms.service: dynamics-ax-platform\nms.technology: \n\n# optional metadata\n\n# ms.search.form: \n# ROBOTS: \naudience: Developer\n# ms.devlang: \nms.reviewer: robinr\nms.search.scope: AX 7.0.0, Operations, UnifiedOperations\n# ms.tgt_pltfrm: \nms.custom: 24821\nms.assetid: 70a4f748-b0bd-44b1-a118-56aacb91481c\nms.search.region: Global\n# ms.search.industry: \nms.author: kuntalme\nms.search.validFrom: 2016-02-28\nms.dyn365.ops.version: AX 7.0.0\n\n---\n\n# Recurring integrations\n\n[!include[banner](../includes/banner.md)]\n\n\nThis article provides information about recurring integrations. The process of data migration, and movement into and out of any enterprise system, is a critical piece that any platform must support. \n\nThe process of data migration, and movement into and out of any enterprise system, is a critical piece that any platform must support. Considerable effort and planning go into building third-party integrations between an enterprise line of business (LOB) system such as Microsoft Dynamics 365 for Finance and Operations, Enterprise edition and various source systems. Microsoft Dynamics AX 2012 enables these scenarios through Application Integration Framework (AIF). For Finance and Operations, we have tried to simplify this process for all parties who are involved, from integration solution builders to customer end users.\n\n## Architecture\nIntegration does the following:\n\n-   It builds on data entities and the rich data management platform (Data Import/Export Framework \\[DIXF\\]).\n-   It enables the exchange of documents/files between Finance and Operations and any third-party application or service.\n-   It supports several document formats, source mapping, Extensible Stylesheet Language Transformations (XSLT), and filters. [![Formats](./media/image001-1024x348.png)](./media/image001.png)\n-   It uses secure REST application programming interfaces (APIs) and authorization mechanisms to receive data from and send data back to integration systems. [![REST](./media/image003-1024x431.png)](./media/image003.png)\n\n## Authorization for the integration REST API\nThe integration REST API uses the same OAuth 2.0 authentication model as the other service endpoints. Before the integrating client application can consume this endpoint, you must create an application ID in Microsoft Azure Active Directory (AAD) and give it appropriate permission to Finance and Operations. When you create and enable a recurring job, you'll be prompted to enter the AAD application ID that will be interacting with that recurring job. Therefore, be sure to note down the application ID.\n\n## Set up a data project and recurring data jobs\n### Create a data project\n\n1.  On the main dashboard, click the **Data management** tile to open the data management workspace.\n2.  Click the **Import or Export** tile to create a new data project. **Note:** If you have an existing data project, click **Load project** on any data project card on the **Data projects** tab.\n3.  Enter a valid job name, data source, and entity name.\n4.  Upload a data file for one or more entities. Make sure that each entity is added, and that no errors occur. **Note:** You can click each entity data card to set up, review, or modify field maps, and to set up XSLT-based transforms that must be applied to inbound data. For export data projects, the entity card also shows a filter link, so that you can set up filters to filter out data. Currently, all recurring data jobs in a data project use the same filter.\n5.  Click **Save**.\n\n### Create a recurring data job\n\n1.  On the **Data project** page, click **Create recurring data job**.\n2.  Enter a valid name and a description for the recurring data job.\n3.  On the **Set up authorization policy** tab, enter the application ID that was generated for your application, and mark it as enabled.\n4.  Expand **Advanced options**, and specify either **File** or **Data package**.\n    -   Specify **File** to indicate that your external integration will push individual files for processing via this recurring data job. In this case, the format of the file that is expected is the same as the format that was specified when the entity was added to the data project.\n    -   Specify **Data package** to indicate that you can push only data package files for processing. A data package is a new format for submitting multiple data files as a single unit that can be used in integration jobs.\n\n5.  Click **Set processing recurrence**, and set a valid recurrence for your data job. [![Processing recurrent](./media/image007-11_16.png)](./media/image007-11_16.png)\n6.  Optional: Click **Set monitoring recurrence**, and provide a monitoring recurrence. **Note:** Currently, the monitoring recurrence enables load monitoring only on your recurring data job queue. No additional policies are supported via this service. You can use this feature to fine-tune the processing recurrence as required by load demand.\n7.  Click **OK**, and then click **Yes** in the confirmation dialog box.\n\n## Manage recurring data jobs\nOpen the System Administration workspace (not module) and click the Data Management IT tile. [![Data management workspace](./media/image011_2016-300x292.png)](./media/image011_2016.png) In this workspace, on the **Recurring data job** tab, click the recurring job to view more details for. The **Management** page contains a grid that lists any messages that are waiting in the queue. This view helps you monitor messages and processing status. [![Management page](./media/image013.jpg)](./media/image013.jpg)\n\n## Submitting data to recurring data jobs\nYou can use well-known integration REST endpoints to integrate with the client, submit documents (import), or poll available documents for download (export). These endpoints support OAuth.\n\n## Integration REST APIs\nThe following set of APIs is used to exchange data between the integration client and Finance and Operations.\n\n### For import (enqueue)\n\nMake an HTTP POST call against the following URL.\n\n    https://<baseurl>/api/connector/enqueue/<activity id>?entity=<entity name>\n\nIn the message body, you can the pass the data as a memory stream. **Example**\n\n    POST https://usncax1aos.cloud.onebox.dynamics.com/en/api/connector/enqueue/%7B6D31E09F-0249-459F-94F0-AAD9C2C47B64%7D?entity=Customer%20Groups\n\nTo get the activity ID, go to the manage recurring job view, and copy and paste the GUID (highlighted in the following screen shot). [![Manage recurring job](./media/image015.jpg)](./media/image015.jpg)\n\n### For export (dequeue)\n\nTo return a data package that contains all the data entities that were defined in that data project, and that the client application can unzip and consume, use the following structure.\n\n    https://<baseurl>/api/connector/enqueue/<activity id>\n\n**Example**\n\n    GET https://usncax1aos.cloud.onebox.dynamics.com/en/api/connector/dequeue/%7BC03BB937-09ED-46DE-86EE-4520D7D7E373%7D\n\nAfter the client downloads the data, an acknowledgment must be sent back to Finance and Operations, so that we can mark the data as received.\n\n### For acknowledging\n\nUse the API.\n\n    https://<baseurl>/api/connector/ack/<activity id>\n\n**Example**\n\n    POST https://usncax1aos.cloud.onebox.dynamics.com/en/api/connector/ack/%7BC03BB937-09ED-46DE-86EE-4520D7D7E373%7D\n\n\n\n","nodes":[{"pos":[4,777],"embed":true,"restype":"x-metadata","content":"# required metadata\n\ntitle: Recurring integrations\ndescription: This article provides information about recurring integrations. The process of data migration, and movement into and out of any enterprise system, is a critical piece that any platform must support. \nauthor: RobinARH\nmanager: AnnBe\nms.date: 06/20/2017\nms.topic: article\nms.prod: \nms.service: dynamics-ax-platform\nms.technology: \n\n# optional metadata\n\n# ms.search.form: \n# ROBOTS: \naudience: Developer\n# ms.devlang: \nms.reviewer: robinr\nms.search.scope: AX 7.0.0, Operations, UnifiedOperations\n# ms.tgt_pltfrm: \nms.custom: 24821\nms.assetid: 70a4f748-b0bd-44b1-a118-56aacb91481c\nms.search.region: Global\n# ms.search.industry: \nms.author: kuntalme\nms.search.validFrom: 2016-02-28\nms.dyn365.ops.version: AX 7.0.0\n","nodes":[{"content":"Recurring integrations","nodes":[{"pos":[0,22],"content":"Recurring integrations","nodes":[{"content":"Recurring integrations","pos":[0,22]}]}],"path":["title"],"extradata":"MT"},{"content":"This article provides information about recurring integrations. The process of data migration, and movement into and out of any enterprise system, is a critical piece that any platform must support.","nodes":[{"pos":[0,198],"content":"This article provides information about recurring integrations. The process of data migration, and movement into and out of any enterprise system, is a critical piece that any platform must support.","nodes":[{"content":"This article provides information about recurring integrations. The process of data migration, and movement into and out of any enterprise system, is a critical piece that any platform must support.","pos":[0,198],"nodes":[{"content":"This article provides information about recurring integrations.","pos":[0,63]},{"content":"The process of data migration, and movement into and out of any enterprise system, is a critical piece that any platform must support.","pos":[64,198]}]}]}],"path":["description"],"extradata":"MT"}],"header":"# required metadata\n","yml":true},{"pos":[785,807],"content":"Recurring integrations","linkify":"Recurring integrations","nodes":[{"content":"Recurring integrations","pos":[0,22]}]},{"content":"This article provides information about recurring integrations.","pos":[853,916]},{"content":"The process of data migration, and movement into and out of any enterprise system, is a critical piece that any platform must support.","pos":[917,1051]},{"content":"The process of data migration, and movement into and out of any enterprise system, is a critical piece that any platform must support.","pos":[1054,1188]},{"content":"Considerable effort and planning go into building third-party integrations between an enterprise line of business (LOB) system such as Microsoft Dynamics 365 for Finance and Operations, Enterprise edition and various source systems.","pos":[1189,1421]},{"content":"Microsoft Dynamics AX 2012 enables these scenarios through Application Integration Framework (AIF).","pos":[1422,1521]},{"content":"For Finance and Operations, we have tried to simplify this process for all parties who are involved, from integration solution builders to customer end users.","pos":[1522,1680]},{"pos":[1685,1697],"content":"Architecture","linkify":"Architecture","nodes":[{"content":"Architecture","pos":[0,12]}]},{"content":"Integration does the following:","pos":[1698,1729]},{"content":"It builds on data entities and the rich data management platform (Data Import/Export Framework <ph id=\"ph1\">\\[</ph>DIXF<ph id=\"ph2\">\\]</ph>).","pos":[1735,1840],"source":"It builds on data entities and the rich data management platform (Data Import/Export Framework \\[DIXF\\])."},{"content":"It enables the exchange of documents/files between Finance and Operations and any third-party application or service.","pos":[1845,1962]},{"content":"It supports several document formats, source mapping, Extensible Stylesheet Language Transformations (XSLT), and filters.","pos":[1967,2088]},{"content":"<bpt id=\"p1\">[</bpt><ph id=\"ph1\">![</ph>Formats<ept id=\"p1\">](./media/image001-1024x348.png)](./media/image001.png)</ept>","pos":[2089,2154],"source":"[![Formats](./media/image001-1024x348.png)](./media/image001.png)"},{"content":"It uses secure REST application programming interfaces (APIs) and authorization mechanisms to receive data from and send data back to integration systems.","pos":[2159,2313]},{"content":"<bpt id=\"p1\">[</bpt><ph id=\"ph1\">![</ph>REST<ept id=\"p1\">](./media/image003-1024x431.png)](./media/image003.png)</ept>","pos":[2314,2376],"source":"[![REST](./media/image003-1024x431.png)](./media/image003.png)"},{"pos":[2381,2423],"content":"Authorization for the integration REST API","linkify":"Authorization for the integration REST API","nodes":[{"content":"Authorization for the integration REST API","pos":[0,42]}]},{"content":"The integration REST API uses the same OAuth 2.0 authentication model as the other service endpoints.","pos":[2424,2525]},{"content":"Before the integrating client application can consume this endpoint, you must create an application ID in Microsoft Azure Active Directory (AAD) and give it appropriate permission to Finance and Operations.","pos":[2526,2732]},{"content":"When you create and enable a recurring job, you'll be prompted to enter the AAD application ID that will be interacting with that recurring job.","pos":[2733,2877]},{"content":"Therefore, be sure to note down the application ID.","pos":[2878,2929]},{"pos":[2934,2979],"content":"Set up a data project and recurring data jobs","linkify":"Set up a data project and recurring data jobs","nodes":[{"content":"Set up a data project and recurring data jobs","pos":[0,45]}]},{"pos":[2984,3005],"content":"Create a data project","linkify":"Create a data project","nodes":[{"content":"Create a data project","pos":[0,21]}]},{"pos":[3011,3107],"content":"On the main dashboard, click the <bpt id=\"p1\">**</bpt>Data management<ept id=\"p1\">**</ept> tile to open the data management workspace.","source":"On the main dashboard, click the **Data management** tile to open the data management workspace."},{"content":"Click the <bpt id=\"p1\">**</bpt>Import or Export<ept id=\"p1\">**</ept> tile to create a new data project.","pos":[3112,3177],"source":"Click the **Import or Export** tile to create a new data project."},{"content":"<bpt id=\"p1\">**</bpt>Note:<ept id=\"p1\">**</ept> If you have an existing data project, click <bpt id=\"p2\">**</bpt>Load project<ept id=\"p2\">**</ept> on any data project card on the <bpt id=\"p3\">**</bpt>Data projects<ept id=\"p3\">**</ept> tab.","pos":[3178,3303],"source":"**Note:** If you have an existing data project, click **Load project** on any data project card on the **Data projects** tab."},{"content":"Enter a valid job name, data source, and entity name.","pos":[3308,3361]},{"content":"Upload a data file for one or more entities.","pos":[3366,3410]},{"content":"Make sure that each entity is added, and that no errors occur.","pos":[3411,3473]},{"content":"<bpt id=\"p1\">**</bpt>Note:<ept id=\"p1\">**</ept> You can click each entity data card to set up, review, or modify field maps, and to set up XSLT-based transforms that must be applied to inbound data.","pos":[3474,3634],"source":"**Note:** You can click each entity data card to set up, review, or modify field maps, and to set up XSLT-based transforms that must be applied to inbound data."},{"content":"For export data projects, the entity card also shows a filter link, so that you can set up filters to filter out data.","pos":[3635,3753]},{"content":"Currently, all recurring data jobs in a data project use the same filter.","pos":[3754,3827]},{"pos":[3832,3847],"content":"Click <bpt id=\"p1\">**</bpt>Save<ept id=\"p1\">**</ept>.","source":"Click **Save**."},{"pos":[3853,3880],"content":"Create a recurring data job","linkify":"Create a recurring data job","nodes":[{"content":"Create a recurring data job","pos":[0,27]}]},{"pos":[3886,3952],"content":"On the <bpt id=\"p1\">**</bpt>Data project<ept id=\"p1\">**</ept> page, click <bpt id=\"p2\">**</bpt>Create recurring data job<ept id=\"p2\">**</ept>.","source":"On the **Data project** page, click **Create recurring data job**."},{"content":"Enter a valid name and a description for the recurring data job.","pos":[3957,4021]},{"pos":[4026,4159],"content":"On the <bpt id=\"p1\">**</bpt>Set up authorization policy<ept id=\"p1\">**</ept> tab, enter the application ID that was generated for your application, and mark it as enabled.","source":"On the **Set up authorization policy** tab, enter the application ID that was generated for your application, and mark it as enabled."},{"pos":[4164,4241],"content":"Expand <bpt id=\"p1\">**</bpt>Advanced options<ept id=\"p1\">**</ept>, and specify either <bpt id=\"p2\">**</bpt>File<ept id=\"p2\">**</ept> or <bpt id=\"p3\">**</bpt>Data package<ept id=\"p3\">**</ept>.","source":"Expand **Advanced options**, and specify either **File** or **Data package**."},{"content":"Specify <bpt id=\"p1\">**</bpt>File<ept id=\"p1\">**</ept> to indicate that your external integration will push individual files for processing via this recurring data job.","pos":[4250,4380],"source":"Specify **File** to indicate that your external integration will push individual files for processing via this recurring data job."},{"content":"In this case, the format of the file that is expected is the same as the format that was specified when the entity was added to the data project.","pos":[4381,4526]},{"content":"Specify <bpt id=\"p1\">**</bpt>Data package<ept id=\"p1\">**</ept> to indicate that you can push only data package files for processing.","pos":[4535,4629],"source":"Specify **Data package** to indicate that you can push only data package files for processing."},{"content":"A data package is a new format for submitting multiple data files as a single unit that can be used in integration jobs.","pos":[4630,4750]},{"content":"Click <bpt id=\"p1\">**</bpt>Set processing recurrence<ept id=\"p1\">**</ept>, and set a valid recurrence for your data job.","pos":[4756,4838],"source":"Click **Set processing recurrence**, and set a valid recurrence for your data job."},{"content":"<bpt id=\"p1\">[</bpt><ph id=\"ph1\">![</ph>Processing recurrent<ept id=\"p1\">](./media/image007-11_16.png)](./media/image007-11_16.png)</ept>","pos":[4839,4920],"source":"[![Processing recurrent](./media/image007-11_16.png)](./media/image007-11_16.png)"},{"content":"Optional: Click <bpt id=\"p1\">**</bpt>Set monitoring recurrence<ept id=\"p1\">**</ept>, and provide a monitoring recurrence.","pos":[4925,5008],"source":"Optional: Click **Set monitoring recurrence**, and provide a monitoring recurrence."},{"content":"<bpt id=\"p1\">**</bpt>Note:<ept id=\"p1\">**</ept> Currently, the monitoring recurrence enables load monitoring only on your recurring data job queue.","pos":[5009,5118],"source":"**Note:** Currently, the monitoring recurrence enables load monitoring only on your recurring data job queue."},{"content":"No additional policies are supported via this service.","pos":[5119,5173]},{"content":"You can use this feature to fine-tune the processing recurrence as required by load demand.","pos":[5174,5265]},{"pos":[5270,5338],"content":"Click <bpt id=\"p1\">**</bpt>OK<ept id=\"p1\">**</ept>, and then click <bpt id=\"p2\">**</bpt>Yes<ept id=\"p2\">**</ept> in the confirmation dialog box.","source":"Click **OK**, and then click **Yes** in the confirmation dialog box."},{"pos":[5343,5369],"content":"Manage recurring data jobs","linkify":"Manage recurring data jobs","nodes":[{"content":"Manage recurring data jobs","pos":[0,26]}]},{"content":"Open the System Administration workspace (not module) and click the Data Management IT tile.","pos":[5370,5462]},{"content":"<bpt id=\"p1\">[</bpt><ph id=\"ph1\">![</ph>Data management workspace<ept id=\"p1\">](./media/image011_2016-300x292.png)](./media/image011_2016.png)</ept> In this workspace, on the <bpt id=\"p2\">**</bpt>Recurring data job<ept id=\"p2\">**</ept> tab, click the recurring job to view more details for.","pos":[5463,5659],"source":"[![Data management workspace](./media/image011_2016-300x292.png)](./media/image011_2016.png) In this workspace, on the **Recurring data job** tab, click the recurring job to view more details for."},{"content":"The <bpt id=\"p1\">**</bpt>Management<ept id=\"p1\">**</ept> page contains a grid that lists any messages that are waiting in the queue.","pos":[5660,5754],"source":" The **Management** page contains a grid that lists any messages that are waiting in the queue."},{"content":"This view helps you monitor messages and processing status.","pos":[5755,5814]},{"content":"<bpt id=\"p1\">[</bpt><ph id=\"ph1\">![</ph>Management page<ept id=\"p1\">](./media/image013.jpg)](./media/image013.jpg)</ept>","pos":[5815,5879],"source":"[![Management page](./media/image013.jpg)](./media/image013.jpg)"},{"pos":[5884,5922],"content":"Submitting data to recurring data jobs","linkify":"Submitting data to recurring data jobs","nodes":[{"content":"Submitting data to recurring data jobs","pos":[0,38]}]},{"content":"You can use well-known integration REST endpoints to integrate with the client, submit documents (import), or poll available documents for download (export).","pos":[5923,6080]},{"content":"These endpoints support OAuth.","pos":[6081,6111]},{"pos":[6116,6137],"content":"Integration REST APIs","linkify":"Integration REST APIs","nodes":[{"content":"Integration REST APIs","pos":[0,21]}]},{"content":"The following set of APIs is used to exchange data between the integration client and Finance and Operations.","pos":[6138,6247]},{"pos":[6253,6273],"content":"For import (enqueue)","linkify":"For import (enqueue)","nodes":[{"content":"For import (enqueue)","pos":[0,20]}]},{"content":"Make an HTTP POST call against the following URL.","pos":[6275,6324]},{"content":"In the message body, you can the pass the data as a memory stream.","pos":[6406,6472]},{"content":"<bpt id=\"p1\">**</bpt>Example<ept id=\"p1\">**</ept>","pos":[6473,6484],"source":"**Example**"},{"content":"To get the activity ID, go to the manage recurring job view, and copy and paste the GUID (highlighted in the following screen shot).","pos":[6634,6766]},{"content":"<bpt id=\"p1\">[</bpt><ph id=\"ph1\">![</ph>Manage recurring job<ept id=\"p1\">](./media/image015.jpg)](./media/image015.jpg)</ept>","pos":[6767,6836],"source":"[![Manage recurring job](./media/image015.jpg)](./media/image015.jpg)"},{"pos":[6842,6862],"content":"For export (dequeue)","linkify":"For export (dequeue)","nodes":[{"content":"For export (dequeue)","pos":[0,20]}]},{"content":"To return a data package that contains all the data entities that were defined in that data project, and that the client application can unzip and consume, use the following structure.","pos":[6864,7048]},{"pos":[7109,7120],"content":"<bpt id=\"p1\">**</bpt>Example<ept id=\"p1\">**</ept>","source":"**Example**"},{"content":"After the client downloads the data, an acknowledgment must be sent back to Finance and Operations, so that we can mark the data as received.","pos":[7244,7385]},{"pos":[7391,7408],"content":"For acknowledging","linkify":"For acknowledging","nodes":[{"content":"For acknowledging","pos":[0,17]}]},{"content":"Use the API.","pos":[7410,7422]},{"pos":[7479,7490],"content":"<bpt id=\"p1\">**</bpt>Example<ept id=\"p1\">**</ept>","source":"**Example**"}]}